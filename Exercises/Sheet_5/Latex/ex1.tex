
\subsection*{(a)}

    Let $x,b \in \R^m, \alpha \in \R$ and $A \in R^{mxm}$. We want to find the gradient of :
    
    \[
    \psi = x^TAx+ b^Tx+\alpha    
    \]

    We have:

    \begin{align*}
        d\psi   &= d(x^TAx+b^Tx+\alpha)\\
                &= dx^TAx+db^Tx+d\alpha\\
                &= dx^TAx+db^Tx\\
                &= x^T(A+A^T)dx +db^Tx \\
                &= x^T(A+A^T)dx +d(b)^Tx+b^Tdx \\
                &= (x^T(A+A^T)+b^T)dx\\
    \end{align*}
So:

\[
D\psi= x^T(A+A^T)+b^T   
\]

\subsection*{(b)}
Let $x_i \in \R^n$ and $y_i \in \{0,1\}$ for $1 \leq i \leq n$ We are looking for the dervative of 
\[
\tau = \sum_{i=1}^n(y_i-\sigma(x_i^T\omega +b))^2 
\]

,where:

\[
\sigma(\alpha) = \frac{1}{1+exp(\alpha)} 
\]

We have:

\begin{align*}
    d\tau   &=d(\sum_{i=1}^n(y_i-\sigma(x_i^T\omega +b))^2 ) \\
            &= \sum_{i=1}^nd((y_i-\sigma(x_i^T\omega +b))^2) \\
            &=\sum_{i=1}^n2(y_i-\sigma(x_i^T\omega +b))d(y_i-\sigma(x_i^T\omega +b))  \\
            &=\sum_{i=1}^n2(y_i-\sigma(x_i^T\omega +b))(dy_i-d\sigma(x_i^T\omega +b))  \\
            &=-2\sum_{i=1}^n(y_i-\sigma(x_i^T\omega +b))(\sigma(x_i^T\omega +b)\cdot(1-\sigma(x_i^T\omega +b))d(x_i^T\omega +b)  \\
            &=-2\sum_{i=1}^n(y_i-\sigma(x_i^T\omega +b))(\sigma(x_i^T\omega +b)\cdot(1-\sigma(x_i^T\omega +b))db
\end{align*}
 So the dervative with respect to b is:

 \[
 D_b \tau =   -2\sum_{i=1}^n(y_i-\sigma(x_i^T\omega +b))(\sigma(x_i^T\omega +b)\cdot(1-\sigma(x_i^T\omega +b))  
 \]

 And for $\omega$ we have :

\begin{align*}
    d\tau       &=-2\sum_{i=1}^n(y_i-\sigma(x_i^T\omega +b))(\sigma(x_i^T\omega +b)\cdot(1-\sigma(x_i^T\omega +b))d(x_i^T\omega +b)  \\
                &=-2\sum_{i=1}^n(y_i-\sigma(x_i^T\omega +b))(\sigma(x_i^T\omega +b)\cdot(1-\sigma(x_i^T\omega +b))x_i^T d\omega
\end{align*}

So we have :

\[
    D_b \omega =    -2\sum_{i=1}^n(y_i-\sigma(x_i^T\omega +b))(\sigma(x_i^T\omega +b)\cdot(1-\sigma(x_i^T\omega +b))x_i^T 
\]





\subsection*{(c)}
Let $x,y \in \R^m, A,B \in \R^{mxm}$ and $\sigma$ the sigmoid function. We want to find the gradient of 

\[
\psi  = ||y-A\sigma(Bx)||_2^2    
\]

By using the definition of the Euclidean Norm we have:

\begin{align*}
    d\psi   &=  d||y-A\sigma(Bx)||_2^2\\
            &= d((\sum_{i=1}^m (y_i -\sigma(Bx)_i)^2)^{\frac{1}{2}})^2\\
            &=  d\sum_{i=1}^m (y_i -\sigma(Bx)_i)^2\\
            &=  \sum_{i=1}^m d(y_i -\sigma(Bx)_i)^2 \\
            &=   \sum_{i=1} 2(y_i -\sigma(Bx)_i)d(y_i -\sigma(Bx)_i)\\
            &=   \sum_{i=1} 2(y_i -\sigma(Bx)_i)(dy_i -d\sigma(Bx)_i)\\
            &=   -\sum_{i=1} 2(y_i -\sigma(Bx)_i)(d\sigma(Bx)_i)\\
            &=   -\sum_{i=1} 2(y_i -\sigma(Bx)_i)(\sigma(Bx)_i\odot(1-\sigma(Bx)_i))dBx_i \\
            &=   -\sum_{i=1} 2(y_i -\sigma(Bx)_i)(\sigma(Bx)_i\odot(1-\sigma(Bx)_i))Bdx_i 
\end{align*}

Then we have : 

\[
D\psi =     -\sum_{i=1} 2(y_i -\sigma(Bx)_i)(-\sigma(Bx)_i\odot(1-\sigma(Bx)_i))B
\]

\subsection*{(d)}

We want to proof that $d(\phi^{\alpha}) = \alpha\phi^{\alpha-1}d\phi$ by induction.

For $\alpha = 1$ we have $d(\phi^{1} = d\phi = 1 \phi^{0}d\phi = d\phi$.

For $\alpha \rightarrow \alpha +1$ we want to prove that $d(\phi^{\alpha+1}) = (\alpha+1)\phi^{(\alpha+1)-1}d\phi$.
\begin{align*}
	d(\phi^{\alpha+1}) &= d(\phi^{\alpha}\phi) \\
	&= d(\phi^{\alpha})\phi + \phi^{\alpha}d(\phi) \\
	&= \alpha\phi^{\alpha-1}\phi d\phi + \phi^{\alpha}d\phi \\
	&=(\alpha\phi^{\alpha-1}\phi+\phi^{\alpha})d\phi \\
	&=(\alpha+1)\phi^{\alpha}d\phi
\end{align*}



